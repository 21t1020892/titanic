import streamlit as st
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from scipy.stats import zscore
# T·∫£i d·ªØ li·ªáu
def phan_gioi_thieu():
    uploaded_file = "titanic.csv"
    try:
        df = pd.read_csv(uploaded_file, delimiter=",")
    except FileNotFoundError:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y t·ªáp d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
        st.stop()
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

    # Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc
    st.subheader("üìå Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc")
    num_rows = st.number_input("Nh·∫≠p s·ªë d√≤ng mu·ªën hi·ªÉn th·ªã:", min_value=1, max_value=len(df), value=10, step=1)
    st.write(df.head(num_rows))    
    st.subheader("üö® Ki·ªÉm tra l·ªói d·ªØ li·ªáu")
                # Ki·ªÉm tra gi√° tr·ªã thi·∫øu
    missing_values = df.isnull().sum()
                # Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p
    duplicate_count = df.duplicated().sum()
                # Ki·ªÉm tra gi√° tr·ªã qu√° l·ªõn (outlier) b·∫±ng Z-score
    outlier_count = {
        col: (abs(zscore(df[col], nan_policy='omit')) > 3).sum()
        for col in df.select_dtypes(include=['number']).columns
    }

    error_report = pd.DataFrame({
        'C·ªôt': df.columns,
        'Gi√° tr·ªã thi·∫øu': missing_values,
        'Outlier': [outlier_count.get(col, 0) for col in df.columns]
    })
    st.table(error_report)
    st.write(f"üîÅ **S·ªë l∆∞·ª£ng d√≤ng b·ªã tr√πng l·∫∑p:** {duplicate_count}")      
    st.write(len(df))     
    st.header("‚öôÔ∏è C√°c b∆∞·ªõc ch√≠nh trong ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
    st.subheader("1Ô∏è‚É£ Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt")
    st.write("""
        M·ªôt s·ªë c·ªôt trong d·ªØ li·ªáu c√≥ th·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn k·∫øt qu·∫£ d·ª± ƒëo√°n ho·∫∑c ch·ª©a qu√° nhi·ªÅu gi√° tr·ªã thi·∫øu.
        B·∫°n c√≥ th·ªÉ ch·ªçn c√°c c·ªôt c·∫ßn lo·∫°i b·ªè d∆∞·ªõi ƒë√¢y:
    """)
    columns_to_drop = st.multiselect("Ch·ªçn c√°c c·ªôt mu·ªën x√≥a:", df.columns)
    if columns_to_drop:
        df.drop(columns=columns_to_drop, inplace=True)
        st.success(f"ƒê√£ x√≥a c√°c c·ªôt: {', '.join(columns_to_drop)}")
    st.subheader("üìå D·ªØ li·ªáu sau khi lo·∫°i b·ªè c·ªôt:")
    st.write(df.head())
    st.subheader("2Ô∏è‚É£ X·ª≠ l√Ω gi√° tr·ªã thi·∫øu")
    st.write("""
        D·ªØ li·ªáu th·ª±c t·∫ø th∆∞·ªùng c√≥ gi√° tr·ªã b·ªã thi·∫øu. Ch√∫ng ta c·∫ßn x·ª≠ l√Ω ƒë·ªÉ tr√°nh ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh.
        B·∫°n c√≥ th·ªÉ ch·ªçn c√°ch ƒëi·ªÅn gi√° tr·ªã thi·∫øu b·∫±ng **Trung b√¨nh (Mean)** ho·∫∑c **Trung v·ªã (Median)**.
    """)

    age_option = st.radio("Ch·ªçn ph∆∞∆°ng ph√°p ƒëi·ªÅn gi√° tr·ªã thi·∫øu cho 'Age':", ("Mean", "Median"))
    if age_option == "Mean":
        df["Age"].fillna(df["Age"].mean(), inplace=True)
    else:
        df["Age"].fillna(df["Age"].median(), inplace=True)

    st.write("C·ªôt 'Embarked' c√≥ s·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu √≠t (2 d√≤ng), s·∫Ω b·ªã x√≥a.")
    df.dropna(subset=["Embarked"], inplace=True)

    st.success("‚úÖ ƒê√£ x·ª≠ l√Ω gi√° tr·ªã thi·∫øu!")

    # Hi·ªÉn th·ªã d·ªØ li·ªáu sau khi x·ª≠ l√Ω gi√° tr·ªã thi·∫øu
    st.subheader("üìå D·ªØ li·ªáu sau khi x·ª≠ l√Ω gi√° tr·ªã thi·∫øu:")
    st.write(df.head(10))

    st.subheader("3Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu")
    st.write("""
        Trong d·ªØ li·ªáu, c√≥ m·ªôt s·ªë c·ªôt ch·ª©a gi√° tr·ªã d·∫°ng ch·ªØ (category). Ta c·∫ßn chuy·ªÉn ƒë·ªïi th√†nh d·∫°ng s·ªë ƒë·ªÉ m√¥ h√¨nh c√≥ th·ªÉ x·ª≠ l√Ω.
        - **C·ªôt "Sex"**: Chuy·ªÉn th√†nh 1 (male), 0 (female).
        - **C·ªôt "Embarked"**:   Chuy·ªÉn th√†nh 1 (Q), 2 (S), 3 (C).
        ```python
            df["Sex"] = df["Sex"].map({"male": 1, "female": 0})  # M√£ h√≥a gi·ªõi t√≠nh
         
            df['Embarked'] = df['Embarked'].map({'Q': 0, 'S': 1, 'C': 2})

        ```
        """)
    df["Sex"] = df["Sex"].map({"male": 1, "female": 0})  # M√£ h√≥a gi·ªõi t√≠nh
    # df = pd.get_dummies(df, columns=["Embarked"], drop_first=True)  # One-Hot Encoding
    df['Embarked'] = df['Embarked'].map({'Q': 0, 'S': 1, 'C': 2})

    st.subheader("4Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë")
    st.write("""
        C√°c gi√° tr·ªã s·ªë c√≥ th·ªÉ c√≥ kho·∫£ng gi√° tr·ªã kh√°c nhau, l√†m ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh. Ta s·∫Ω chu·∫©n h√≥a "Age" v√† "Fare" v·ªÅ c√πng m·ªôt thang ƒëo b·∫±ng StandardScaler.
        
        ```python
            scaler = StandardScaler()
            df[["Age", "Fare"]] = scaler.fit_transform(df[["Age", "Fare"]])

        ```
        """)
    scaler = StandardScaler()
    df[["Age", "Fare"]] = scaler.fit_transform(df[["Age", "Fare"]])
    st.write("D·ªØ li·ªáu sau khi x·ª≠ l√Ω:")
    st.write(df.head(10))
    df.to_csv("processed_titanic.csv", index=False)  # L∆∞u m√† kh√¥ng k√®m ch·ªâ m·ª•c
    st.subheader("5Ô∏è‚É£ Chia d·ªØ li·ªáu th√†nh t·∫≠p Train, Validation, v√† Test")
    st.write("""
        ### üìå Chia t·∫≠p d·ªØ li·ªáu
        B·∫°n c√≥ th·ªÉ ch·ªçn t·ª∑ l·ªá d·ªØ li·ªáu d√†nh cho **Train**, ph·∫ßn c√≤n l·∫°i s·∫Ω ƒë∆∞·ª£c chia ƒë·ªÅu cho **Validation** v√† **Test**.
    """)
    # Ng∆∞·ªùi d√πng ch·ªçn t·ª∑ l·ªá Train (70% m·∫∑c ƒë·ªãnh)
    train_size = st.slider("Ch·ªçn ph·∫ßn trƒÉm d·ªØ li·ªáu d√πng ƒë·ªÉ Train:", min_value=50, max_value=80, value=70, step=5)
    # T√≠nh to√°n t·ª∑ l·ªá Validation & Test
    val_test_size = (100 - train_size) / 2 / 100  # Chia ƒë·ªÅu cho Validation v√† Test
    train_size /= 100  # Chuy·ªÉn train_size v·ªÅ d·∫°ng th·∫≠p ph√¢n
    # Chia d·ªØ li·ªáu
    X = df.drop(columns=["Survived"])  # Bi·∫øn ƒë·∫ßu v√†o
    y = df["Survived"]  # Nh√£n
    # Chia d·ªØ li·ªáu th√†nh Train v√† (Validation + Test)
    X_train_full, X_test, y_train_full, y_test = train_test_split(
        X, y, test_size=(1 - train_size), stratify=y, random_state=42
    )
    # Chia (Validation + Test) th√†nh Validation v√† Test
    X_val, X_test, y_val, y_test = train_test_split(
        X_test, y_test, test_size=0.5, stratify=y_test, random_state=42
    )
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ chia
    st.write(f"üìä **T·ª∑ l·ªá chia d·ªØ li·ªáu:**")
    st.write(f"- **Train**: {train_size*100:.0f}% ({len(X_train_full)} m·∫´u)")
    st.write(f"- **Validation**: {val_test_size*100:.1f}% ({len(X_val)} m·∫´u)")
    st.write(f"- **Test**: {val_test_size*100:.1f}% ({len(X_test)} m·∫´u)")
    st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
    return  X_train_full, X_val, X_test, y_train_full, y_val, y_test
def phan_train(X_train, y_train, X_val, y_val, X_test, y_test):
    st.title("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh")
    st.subheader(" m√¥ h√¨nh Random Forest")
    st.write(f"""
        M√¥ h√¨nh Random Forest l√† m·ªôt m√¥ h√¨nh m·∫°nh m·∫Ω v√† linh ho·∫°t, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c b√†i to√°n ph√¢n lo·∫°i v√† h·ªìi quy.
        ∆Øu ƒëi·ªÉm:   
        - X·ª≠ l√Ω t·ªët v·ªõi d·ªØ li·ªáu l·ªõn.
        - Kh√¥ng y√™u c·∫ßu chu·∫©n h√≥a d·ªØ li·ªáu.
        - D·ªÖ d√†ng x·ª≠ l√Ω overfitting.
        Nh∆∞·ª£c ƒëi·ªÉm:
        - Kh√¥ng hi·ªáu qu·∫£ v·ªõi d·ªØ li·ªáu c√≥ nhi·ªÅu gi√° tr·ªã thi·∫øu.
        - M·∫•t hi·ªáu su·∫•t khi s·ªë l∆∞·ª£ng c√¢y l·ªõn.
        - Kh√¥ng th·ªÉ hi·ªÉn th·ªã qu√° tr√¨nh h·ªçc.
        
        Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng m√¥ h√¨nh Random Forest ƒë·ªÉ d·ª± ƒëo√°n kh·∫£ nƒÉng s·ªëng s√≥t tr√™n t√†u Titanic.
        ```python
            from sklearn.ensemble import RandomForestClassifier

            # Kh·ªüi t·∫°o m√¥ h√¨nh
            model = RandomForestClassifier(random_state=42)

            # Hu·∫•n luy·ªán m√¥ h√¨nh
            model.fit(X_train, y_train)

        ```
        """)
    # Kh·ªüi t·∫°o m√¥ h√¨nh
    model = RandomForestClassifier(random_state=42)
    # Hu·∫•n luy·ªán m√¥ h√¨nh
    model.fit(X_train, y_train)
    st.write("üéØ ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng Cross-Validation")
    st.markdown("""
    Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng `cross_val_score` t·ª´ `sklearn.model_selection`:

    ```python
    from sklearn.model_selection import cross_val_score

    # ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng cross-validation (5-Fold CV)
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
    ```
    
    """)
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
    st.write(f"Cross-validation scores: {cv_scores}")
    st.write(f"Mean CV Accuracy: {cv_scores.mean():.4f}")
    model.fit(X_train, y_train)
    y_val_pred = model.predict(X_val)
    y_test_pred = model.predict(X_test)
    valid_acc = accuracy_score(y_val, y_val_pred)
    test_acc = accuracy_score(y_test, y_test_pred)
    st.write(f"‚úÖ Validation Accuracy: {valid_acc:.4f}")
    st.write(f"‚úÖ Test Accuracy: {test_acc:.4f}")
    return model, valid_acc, test_acc
def test_model(model):
    df = pd.read_csv("processed_titanic.csv")
    st.write("### Ki·ªÉm tra m√¥ h√¨nh v·ªõi gi√° tr·ªã nh·∫≠p v√†o")
    # 1Ô∏è‚É£ Li·ªát k√™ c√°c c·ªôt c·ªßa DataFrame
    feature_columns = df.drop(columns=["Survived"]).columns
    st.write("üîπ C√°c c·ªôt ƒë·∫ßu v√†o:", feature_columns.tolist())
    # 2Ô∏è‚É£ T·∫°o input cho t·ª´ng c·ªôt
    input_data = {}
    for col in feature_columns:
        input_data[col] = st.number_input(f"Nh·∫≠p gi√° tr·ªã cho {col}", value=0.0)
    # 3Ô∏è‚É£ Chuy·ªÉn th√†nh DataFrame
    input_df = pd.DataFrame([input_data])
    # 4Ô∏è‚É£ D·ª± ƒëo√°n v·ªõi model
    if st.button("D·ª± ƒëo√°n"):
        prediction = model.predict(input_df)
        result = "üõë Kh√¥ng s·ªëng s√≥t" if prediction[0] == 0 else "‚úÖ S·ªëng s√≥t"
        st.success(f"üîÆ D·ª± ƒëo√°n k·∫øt qu·∫£: {result}")

def report():
    X_train, X_val, X_test, y_train, y_val, y_test = phan_gioi_thieu()
    model, valid_acc, test_acc = phan_train(X_train, y_train, X_val, y_val, X_test, y_test)
    test_model(model)
if __name__ == "__main__":
    report()